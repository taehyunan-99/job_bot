# Job Bot Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** ë§¤ì£¼ í† ìš”ì¼ 09:00 KSTì— ì›í‹°ë“œÂ·ì‚¬ëŒì¸Â·ë§í¬ë“œì¸ì—ì„œ ë°ì´í„° ì§ë¬´ ê³µê³ ë¥¼ ìˆ˜ì§‘í•´ ìŠ¬ë™ìœ¼ë¡œ ë°œì†¡í•˜ëŠ” GitHub Actions ë´‡

**Architecture:** Python ìŠ¤í¬ë¦½íŠ¸ê°€ ê° í”Œë«í¼ì„ í¬ë¡¤ë§í•˜ê³ , seen_jobs.jsonìœ¼ë¡œ ì¤‘ë³µì„ ì œê±°í•œ ë’¤, ìŠ¬ë™ Webhookìœ¼ë¡œ í¬ë§·ëœ ë©”ì‹œì§€ë¥¼ ë°œì†¡í•œë‹¤. GitHub Actions cronì´ ë§¤ì£¼ ì‹¤í–‰ì„ ë‹´ë‹¹í•œë‹¤.

**Tech Stack:** Python 3.11, requests, BeautifulSoup4, playwright, GitHub Actions, Slack Incoming Webhook

---

### Task 1: í”„ë¡œì íŠ¸ ê¸°ë°˜ ì„¤ì •

**Files:**
- Create: `requirements.txt`
- Create: `main.py`
- Create: `seen_jobs.json`
- Create: `.gitignore`

**Step 1: requirements.txt ì‘ì„±**

```
requests==2.31.0
beautifulsoup4==4.12.2
playwright==1.40.0
python-dotenv==1.0.0
```

**Step 2: seen_jobs.json ì´ˆê¸°í™”**

```json
[]
```

**Step 3: .gitignore ì‘ì„±**

```
.env
__pycache__/
*.pyc
.playwright/
```

**Step 4: main.py ë¼ˆëŒ€ ì‘ì„±**

```python
import json
from scrapers.wanted import scrape_wanted
from scrapers.saramin import scrape_saramin
from scrapers.linkedin import scrape_linkedin
from notifier.slack import send_slack_message
from utils.dedup import filter_new_jobs

SEEN_JOBS_PATH = "seen_jobs.json"

def load_seen_jobs():
    with open(SEEN_JOBS_PATH, "r") as f:
        return set(json.load(f))

def save_seen_jobs(seen):
    with open(SEEN_JOBS_PATH, "w") as f:
        json.dump(list(seen), f)

def main():
    seen = load_seen_jobs()

    all_jobs = []
    all_jobs += scrape_wanted()
    all_jobs += scrape_saramin()
    all_jobs += scrape_linkedin()

    new_jobs, updated_seen = filter_new_jobs(all_jobs, seen)
    save_seen_jobs(updated_seen)

    if new_jobs:
        send_slack_message(new_jobs)
    else:
        print("ìƒˆ ê³µê³  ì—†ìŒ")

if __name__ == "__main__":
    main()
```

**Step 5: Commit**

```bash
git add requirements.txt main.py seen_jobs.json .gitignore
git commit -m "feat: init project structure"
```

---

### Task 2: ì¤‘ë³µ ì œê±° ìœ í‹¸ë¦¬í‹°

**Files:**
- Create: `utils/__init__.py`
- Create: `utils/dedup.py`
- Create: `tests/test_dedup.py`

**Step 1: ì‹¤íŒ¨ í…ŒìŠ¤íŠ¸ ì‘ì„±**

```python
# tests/test_dedup.py
from utils.dedup import filter_new_jobs

def test_filters_seen_jobs():
    jobs = [
        {"id": "wanted-123", "title": "DS", "company": "ì¹´ì¹´ì˜¤"},
        {"id": "saramin-456", "title": "MLE", "company": "ë„¤ì´ë²„"},
    ]
    seen = {"wanted-123"}
    new_jobs, updated_seen = filter_new_jobs(jobs, seen)
    assert len(new_jobs) == 1
    assert new_jobs[0]["id"] == "saramin-456"
    assert "saramin-456" in updated_seen
    assert "wanted-123" in updated_seen

def test_empty_jobs():
    new_jobs, updated_seen = filter_new_jobs([], set())
    assert new_jobs == []
    assert updated_seen == set()
```

**Step 2: í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ í™•ì¸**

```bash
pytest tests/test_dedup.py -v
```
Expected: FAIL (ImportError)

**Step 3: êµ¬í˜„**

```python
# utils/__init__.py  (ë¹ˆ íŒŒì¼)

# utils/dedup.py
def filter_new_jobs(jobs, seen: set):
    new_jobs = []
    for job in jobs:
        if job["id"] not in seen:
            new_jobs.append(job)
            seen.add(job["id"])
    return new_jobs, seen
```

**Step 4: í…ŒìŠ¤íŠ¸ í†µê³¼ í™•ì¸**

```bash
pytest tests/test_dedup.py -v
```
Expected: PASS

**Step 5: Commit**

```bash
git add utils/ tests/test_dedup.py
git commit -m "feat: add dedup utility"
```

---

### Task 3: ì›í‹°ë“œ í¬ë¡¤ëŸ¬

**Files:**
- Create: `scrapers/__init__.py`
- Create: `scrapers/wanted.py`
- Create: `tests/test_wanted.py`

**Step 1: ì‹¤íŒ¨ í…ŒìŠ¤íŠ¸ ì‘ì„±**

```python
# tests/test_wanted.py
from unittest.mock import patch, MagicMock
from scrapers.wanted import scrape_wanted

def test_scrape_wanted_returns_list():
    mock_response = {
        "data": [
            {
                "id": 12345,
                "position": {"name": "ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸"},
                "company": {"name": "ì¹´ì¹´ì˜¤"},
                "skill_tags": [{"keyword": "Python"}, {"keyword": "SQL"}],
                "job_category": {"name": "ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§"},
            }
        ]
    }
    with patch("scrapers.wanted.requests.get") as mock_get:
        mock_get.return_value.json.return_value = mock_response
        mock_get.return_value.status_code = 200
        jobs = scrape_wanted()
    assert len(jobs) == 1
    assert jobs[0]["id"] == "wanted-12345"
    assert jobs[0]["company"] == "ì¹´ì¹´ì˜¤"
    assert "Python" in jobs[0]["skills"]
```

**Step 2: í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ í™•ì¸**

```bash
pytest tests/test_wanted.py -v
```

**Step 3: êµ¬í˜„**

```python
# scrapers/__init__.py  (ë¹ˆ íŒŒì¼)

# scrapers/wanted.py
import requests

WANTED_API = "https://www.wanted.co.kr/api/v4/jobs"
KEYWORDS = ["ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸", "ë°ì´í„° ì—”ì§€ë‹ˆì–´", "ML ì—”ì§€ë‹ˆì–´", "ë¨¸ì‹ ëŸ¬ë‹", "data scientist"]

HEADERS = {
    "User-Agent": "Mozilla/5.0",
    "wanted-user-language": "ko",
}

def scrape_wanted():
    jobs = []
    for keyword in KEYWORDS:
        params = {
            "job_sort": "job.latest_order",
            "years": -1,
            "limit": 20,
            "offset": 0,
            "tag_type_names": keyword,
        }
        resp = requests.get(WANTED_API, params=params, headers=HEADERS)
        if resp.status_code != 200:
            continue
        data = resp.json().get("data", [])
        for item in data:
            jobs.append({
                "id": f"wanted-{item['id']}",
                "title": item["position"]["name"],
                "company": item["company"]["name"],
                "skills": [t["keyword"] for t in item.get("skill_tags", [])],
                "description": item.get("job_category", {}).get("name", ""),
                "url": f"https://www.wanted.co.kr/wd/{item['id']}",
                "source": "ì›í‹°ë“œ",
            })
    # ì¤‘ë³µ ì œê±° (ê°™ì€ id)
    seen_ids = set()
    unique = []
    for j in jobs:
        if j["id"] not in seen_ids:
            seen_ids.add(j["id"])
            unique.append(j)
    return unique
```

**Step 4: í…ŒìŠ¤íŠ¸ í†µê³¼ í™•ì¸**

```bash
pytest tests/test_wanted.py -v
```

**Step 5: Commit**

```bash
git add scrapers/ tests/test_wanted.py
git commit -m "feat: add wanted scraper"
```

---

### Task 4: ì‚¬ëŒì¸ í¬ë¡¤ëŸ¬

**Files:**
- Create: `scrapers/saramin.py`
- Create: `tests/test_saramin.py`

**Step 1: ì‹¤íŒ¨ í…ŒìŠ¤íŠ¸ ì‘ì„±**

```python
# tests/test_saramin.py
from unittest.mock import patch, MagicMock
from scrapers.saramin import scrape_saramin

def test_scrape_saramin_returns_list():
    mock_html = """
    <div class="item_recruit">
        <div class="area_job">
            <h2 class="job_tit"><a href="/zf_user/jobs/relay/view?rec_idx=99999" title="ë°ì´í„° ë¶„ì„ê°€">ë°ì´í„° ë¶„ì„ê°€</a></h2>
            <div class="job_condition">
                <span><a href="#">ë„¤ì´ë²„</a></span>
            </div>
            <div class="job_sector">
                <a>Python</a><a>SQL</a>
            </div>
        </div>
    </div>
    """
    with patch("scrapers.saramin.requests.get") as mock_get:
        mock_get.return_value.text = mock_html
        mock_get.return_value.status_code = 200
        jobs = scrape_saramin()
    assert isinstance(jobs, list)
```

**Step 2: í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ í™•ì¸**

```bash
pytest tests/test_saramin.py -v
```

**Step 3: êµ¬í˜„**

```python
# scrapers/saramin.py
import requests
from bs4 import BeautifulSoup

SARAMIN_URL = "https://www.saramin.co.kr/zf_user/search/recruit"
KEYWORDS = ["ë°ì´í„°ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸", "ë°ì´í„°ì—”ì§€ë‹ˆì–´", "ë¨¸ì‹ ëŸ¬ë‹ì—”ì§€ë‹ˆì–´"]

HEADERS = {"User-Agent": "Mozilla/5.0"}

def scrape_saramin():
    jobs = []
    for keyword in KEYWORDS:
        params = {
            "searchType": "search",
            "searchword": keyword,
            "recruitPage": 1,
            "recruitPageCount": 20,
            "recruitSort": "reg_dt",
        }
        resp = requests.get(SARAMIN_URL, params=params, headers=HEADERS)
        if resp.status_code != 200:
            continue
        soup = BeautifulSoup(resp.text, "html.parser")
        items = soup.select(".item_recruit")
        for item in items:
            title_el = item.select_one(".job_tit a")
            company_el = item.select_one(".job_condition span a")
            skill_els = item.select(".job_sector a")
            if not title_el:
                continue
            href = title_el.get("href", "")
            rec_idx = href.split("rec_idx=")[-1].split("&")[0] if "rec_idx=" in href else href
            jobs.append({
                "id": f"saramin-{rec_idx}",
                "title": title_el.get_text(strip=True),
                "company": company_el.get_text(strip=True) if company_el else "",
                "skills": [s.get_text(strip=True) for s in skill_els],
                "description": "",
                "url": f"https://www.saramin.co.kr{href}",
                "source": "ì‚¬ëŒì¸",
            })
    seen_ids = set()
    unique = []
    for j in jobs:
        if j["id"] not in seen_ids:
            seen_ids.add(j["id"])
            unique.append(j)
    return unique
```

**Step 4: í…ŒìŠ¤íŠ¸ í†µê³¼ í™•ì¸**

```bash
pytest tests/test_saramin.py -v
```

**Step 5: Commit**

```bash
git add scrapers/saramin.py tests/test_saramin.py
git commit -m "feat: add saramin scraper"
```

---

### Task 5: ë§í¬ë“œì¸ í¬ë¡¤ëŸ¬

**Files:**
- Create: `scrapers/linkedin.py`
- Create: `tests/test_linkedin.py`

**Step 1: ì‹¤íŒ¨ í…ŒìŠ¤íŠ¸ ì‘ì„±**

```python
# tests/test_linkedin.py
from unittest.mock import patch
from scrapers.linkedin import scrape_linkedin

def test_scrape_linkedin_returns_list():
    mock_html = """
    <ul class="jobs-search__results-list">
      <li>
        <a class="base-card__full-link" href="https://www.linkedin.com/jobs/view/123456">
        </a>
        <h3 class="base-search-card__title">Data Scientist</h3>
        <h4 class="base-search-card__subtitle">Kakao</h4>
      </li>
    </ul>
    """
    with patch("scrapers.linkedin.requests.get") as mock_get:
        mock_get.return_value.text = mock_html
        mock_get.return_value.status_code = 200
        jobs = scrape_linkedin()
    assert isinstance(jobs, list)
```

**Step 2: í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ í™•ì¸**

```bash
pytest tests/test_linkedin.py -v
```

**Step 3: êµ¬í˜„**

```python
# scrapers/linkedin.py
import requests
from bs4 import BeautifulSoup

LINKEDIN_URL = "https://www.linkedin.com/jobs/search/"
KEYWORDS = ["data scientist", "data engineer", "machine learning engineer"]

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
}

def scrape_linkedin():
    jobs = []
    for keyword in KEYWORDS:
        params = {
            "keywords": keyword,
            "location": "South Korea",
            "f_TPR": "r604800",  # ìµœê·¼ 1ì£¼ì¼
            "sortBy": "DD",
        }
        resp = requests.get(LINKEDIN_URL, params=params, headers=HEADERS)
        if resp.status_code != 200:
            continue
        soup = BeautifulSoup(resp.text, "html.parser")
        items = soup.select(".base-card")
        for item in items:
            link_el = item.select_one("a.base-card__full-link")
            title_el = item.select_one(".base-search-card__title")
            company_el = item.select_one(".base-search-card__subtitle")
            if not link_el or not title_el:
                continue
            url = link_el.get("href", "").split("?")[0]
            job_id = url.rstrip("/").split("/")[-1]
            jobs.append({
                "id": f"linkedin-{job_id}",
                "title": title_el.get_text(strip=True),
                "company": company_el.get_text(strip=True) if company_el else "",
                "skills": [],
                "description": "",
                "url": url,
                "source": "ë§í¬ë“œì¸",
            })
    seen_ids = set()
    unique = []
    for j in jobs:
        if j["id"] not in seen_ids:
            seen_ids.add(j["id"])
            unique.append(j)
    return unique
```

**Step 4: í…ŒìŠ¤íŠ¸ í†µê³¼ í™•ì¸**

```bash
pytest tests/test_linkedin.py -v
```

**Step 5: Commit**

```bash
git add scrapers/linkedin.py tests/test_linkedin.py
git commit -m "feat: add linkedin scraper"
```

---

### Task 6: ìŠ¬ë™ ë…¸í‹°íŒŒì´ì–´

**Files:**
- Create: `notifier/__init__.py`
- Create: `notifier/slack.py`
- Create: `tests/test_slack.py`

**Step 1: ì‹¤íŒ¨ í…ŒìŠ¤íŠ¸ ì‘ì„±**

```python
# tests/test_slack.py
from unittest.mock import patch, MagicMock
from notifier.slack import format_message, send_slack_message

def test_format_message_contains_title():
    jobs = [
        {
            "source": "ì›í‹°ë“œ",
            "title": "ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸",
            "company": "ì¹´ì¹´ì˜¤",
            "skills": ["Python", "SQL"],
            "description": "ì¶”ì²œ ì‹œìŠ¤í…œ ê°œë°œ",
            "url": "https://www.wanted.co.kr/wd/12345",
        }
    ]
    msg = format_message(jobs)
    assert "ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸" in msg
    assert "ì¹´ì¹´ì˜¤" in msg
    assert "Python" in msg

def test_send_slack_message_calls_webhook():
    jobs = [{"source": "ì›í‹°ë“œ", "title": "DS", "company": "A", "skills": [], "description": "", "url": "http://x"}]
    with patch("notifier.slack.requests.post") as mock_post:
        mock_post.return_value.status_code = 200
        send_slack_message(jobs)
        mock_post.assert_called_once()
```

**Step 2: í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ í™•ì¸**

```bash
pytest tests/test_slack.py -v
```

**Step 3: êµ¬í˜„**

```python
# notifier/__init__.py  (ë¹ˆ íŒŒì¼)

# notifier/slack.py
import os
import requests
from datetime import date
from collections import defaultdict

SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL", "")

def format_message(jobs: list) -> str:
    today = date.today().strftime("%Y-%m-%d")
    lines = [f"ğŸ“Š *[ë°ì´í„° ì§ë¬´ ì£¼ê°„ ë¸Œë¦¬í•‘]* {today}\n"]

    by_source = defaultdict(list)
    for job in jobs:
        by_source[job["source"]].append(job)

    for source, source_jobs in by_source.items():
        lines.append(f"\nâœ… *{source}* ({len(source_jobs)}ê±´)")
        for job in source_jobs:
            skills = ", ".join(job["skills"]) if job["skills"] else "ì •ë³´ ì—†ìŒ"
            desc = job["description"] if job["description"] else "ì •ë³´ ì—†ìŒ"
            lines.append(
                f"â€¢ *{job['company']}* - {job['title']}\n"
                f"  ğŸ›  {skills}\n"
                f"  ğŸ“‹ {desc}\n"
                f"  ğŸ”— {job['url']}"
            )

    return "\n".join(lines)

def send_slack_message(jobs: list):
    if not SLACK_WEBHOOK_URL:
        raise ValueError("SLACK_WEBHOOK_URL í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    message = format_message(jobs)
    payload = {"text": message}
    resp = requests.post(SLACK_WEBHOOK_URL, json=payload)
    if resp.status_code != 200:
        raise RuntimeError(f"ìŠ¬ë™ ë°œì†¡ ì‹¤íŒ¨: {resp.status_code} {resp.text}")
```

**Step 4: í…ŒìŠ¤íŠ¸ í†µê³¼ í™•ì¸**

```bash
pytest tests/test_slack.py -v
```

**Step 5: Commit**

```bash
git add notifier/ tests/test_slack.py
git commit -m "feat: add slack notifier"
```

---

### Task 7: GitHub Actions ì›Œí¬í”Œë¡œìš°

**Files:**
- Create: `.github/workflows/job_bot.yml`

**Step 1: ì›Œí¬í”Œë¡œìš° ì‘ì„±**

```yaml
# .github/workflows/job_bot.yml
name: Job Bot

on:
  schedule:
    # ë§¤ì£¼ í† ìš”ì¼ 00:00 UTC = 09:00 KST
    - cron: "0 0 * * 6"
  workflow_dispatch:  # ìˆ˜ë™ ì‹¤í–‰ ê°€ëŠ¥

jobs:
  run-bot:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Run job bot
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        run: python main.py

      - name: Commit updated seen_jobs.json
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add seen_jobs.json
          git diff --cached --quiet || git commit -m "chore: update seen_jobs"
          git push
```

**Step 2: GitHub Secrets ì„¤ì • ì•ˆë‚´**

GitHub ë ˆí¬ â†’ Settings â†’ Secrets and variables â†’ Actions â†’ New repository secret
- Name: `SLACK_WEBHOOK_URL`
- Value: Slack Incoming Webhook URL

**Step 3: Commit**

```bash
git add .github/workflows/job_bot.yml
git commit -m "feat: add github actions workflow"
```

---

### Task 8: í†µí•© í…ŒìŠ¤íŠ¸ ë° ë¡œì»¬ ì‹¤í–‰ ê²€ì¦

**Files:**
- Create: `.env.example`
- Create: `tests/test_main.py`

**Step 1: .env.example ì‘ì„±**

```
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/WEBHOOK/URL
```

**Step 2: í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„±**

```python
# tests/test_main.py
from unittest.mock import patch, MagicMock
from main import main

def test_main_runs_without_error():
    mock_jobs = [
        {"id": "wanted-1", "title": "DS", "company": "A", "skills": ["Python"], "description": "ë¶„ì„", "url": "http://x", "source": "ì›í‹°ë“œ"}
    ]
    with patch("main.scrape_wanted", return_value=mock_jobs), \
         patch("main.scrape_saramin", return_value=[]), \
         patch("main.scrape_linkedin", return_value=[]), \
         patch("main.send_slack_message") as mock_slack:
        main()
        mock_slack.assert_called_once()
```

**Step 3: ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰**

```bash
pytest tests/ -v
```
Expected: ëª¨ë“  í…ŒìŠ¤íŠ¸ PASS

**Step 4: Commit**

```bash
git add .env.example tests/test_main.py
git commit -m "test: add integration test and env example"
```

---

## ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] Task 1: í”„ë¡œì íŠ¸ ê¸°ë°˜ ì„¤ì •
- [ ] Task 2: ì¤‘ë³µ ì œê±° ìœ í‹¸ë¦¬í‹°
- [ ] Task 3: ì›í‹°ë“œ í¬ë¡¤ëŸ¬
- [ ] Task 4: ì‚¬ëŒì¸ í¬ë¡¤ëŸ¬
- [ ] Task 5: ë§í¬ë“œì¸ í¬ë¡¤ëŸ¬
- [ ] Task 6: ìŠ¬ë™ ë…¸í‹°íŒŒì´ì–´
- [ ] Task 7: GitHub Actions ì›Œí¬í”Œë¡œìš°
- [ ] Task 8: í†µí•© í…ŒìŠ¤íŠ¸

## ìŠ¬ë™ Webhook ì„¤ì • ë°©ë²•

1. [Slack API](https://api.slack.com/apps) â†’ Create New App â†’ From scratch
2. Incoming Webhooks â†’ Activate â†’ Add New Webhook to Workspace
3. ì±„ë„ ì„ íƒ í›„ Webhook URL ë³µì‚¬
4. GitHub Secretsì— `SLACK_WEBHOOK_URL`ë¡œ ë“±ë¡
